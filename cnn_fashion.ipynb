{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras fashion",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argence-main-pathvision/StatsModel/blob/master/cnn_fashion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FBSVw6l1e5JR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEUNrq9bf94G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0uPc2n6e-bK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as   K\n",
        " \n",
        "class MiniVGGNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        " \n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        " \n",
        "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        " \n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(512))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\t#model.add(Dropout(0.5))\n",
        " \n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        " \n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7eJmWsfgKkA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        " \n",
        "# import the necessary packages\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "# initialize the number of epochs to train for, base learning rate,\n",
        "# and batch size\n",
        "NUM_EPOCHS = 25\n",
        "INIT_LR = 1e-2\n",
        "BS = 32\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6sVLFCk7nL6r",
        "colab_type": "code",
        "outputId": "b049d64b-5675-429a-c11b-d7bbecbcf9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,679,082\n",
            "Trainable params: 1,677,674\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FyaBpvm7oC6b",
        "colab_type": "code",
        "outputId": "0cd52472-d182-44a2-ad31-61d3f1e6ec74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# grab the Fashion MNIST dataset (if this is your first time running\n",
        "# this the dataset will be automatically downloaded)\n",
        "print(\"[INFO] loading Fashion MNIST...\")\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        " \n",
        "# if we are using \"channels first\" ordering, then reshape the design\n",
        "# matrix such that the matrix is:\n",
        "# \tnum_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
        "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
        " \n",
        "# otherwise, we are using \"channels last\" ordering, so the design\n",
        "# matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading Fashion MNIST...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hj7soOrBozA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        " \n",
        "# one-hot encode the training and testing labels\n",
        "trainY = np_utils.to_categorical(trainY, 10)\n",
        "testY = np_utils.to_categorical(testY, 10)\n",
        " \n",
        "# initialize the label names\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NGPsAj9Xo6DV",
        "colab_type": "code",
        "outputId": "2469ad65-d2ea-4182-cd9c-e2aa0f594f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "cell_type": "code",
      "source": [
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        " \n",
        "# train the network\n",
        "print(\"[INFO] training model...\")\n",
        "H = model.fit(trainX, trainY,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tbatch_size=BS, epochs=NUM_EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training model...\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 30s 498us/step - loss: 0.4326 - acc: 0.8482 - val_loss: 0.3361 - val_acc: 0.8783\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.2835 - acc: 0.8963 - val_loss: 0.2560 - val_acc: 0.9073\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 28s 472us/step - loss: 0.2446 - acc: 0.9116 - val_loss: 0.2398 - val_acc: 0.9110\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.2175 - acc: 0.9202 - val_loss: 0.2307 - val_acc: 0.9136\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 28s 472us/step - loss: 0.2023 - acc: 0.9253 - val_loss: 0.2144 - val_acc: 0.9187\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 28s 472us/step - loss: 0.1893 - acc: 0.9302 - val_loss: 0.2040 - val_acc: 0.9256\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1795 - acc: 0.9351 - val_loss: 0.2126 - val_acc: 0.9217\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 28s 473us/step - loss: 0.1714 - acc: 0.9370 - val_loss: 0.1961 - val_acc: 0.9294\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 28s 472us/step - loss: 0.1635 - acc: 0.9404 - val_loss: 0.1948 - val_acc: 0.9300\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 28s 475us/step - loss: 0.1571 - acc: 0.9425 - val_loss: 0.1948 - val_acc: 0.9298\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1523 - acc: 0.9433 - val_loss: 0.1921 - val_acc: 0.9327\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1465 - acc: 0.9461 - val_loss: 0.1898 - val_acc: 0.9329\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1419 - acc: 0.9480 - val_loss: 0.1886 - val_acc: 0.9325\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1382 - acc: 0.9502 - val_loss: 0.1893 - val_acc: 0.9339\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 28s 468us/step - loss: 0.1337 - acc: 0.9505 - val_loss: 0.1898 - val_acc: 0.9331\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1291 - acc: 0.9518 - val_loss: 0.1873 - val_acc: 0.9358\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 28s 468us/step - loss: 0.1269 - acc: 0.9539 - val_loss: 0.1943 - val_acc: 0.9325\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1220 - acc: 0.9553 - val_loss: 0.1860 - val_acc: 0.9347\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 28s 469us/step - loss: 0.1194 - acc: 0.9565 - val_loss: 0.1864 - val_acc: 0.9356\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1162 - acc: 0.9586 - val_loss: 0.1854 - val_acc: 0.9346\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 28s 470us/step - loss: 0.1155 - acc: 0.9580 - val_loss: 0.1866 - val_acc: 0.9347\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1109 - acc: 0.9598 - val_loss: 0.1881 - val_acc: 0.9357\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 28s 466us/step - loss: 0.1088 - acc: 0.9600 - val_loss: 0.1869 - val_acc: 0.9352\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1094 - acc: 0.9597 - val_loss: 0.1857 - val_acc: 0.9376\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1048 - acc: 0.9619 - val_loss: 0.1919 - val_acc: 0.9344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilk1PAopo-Xl",
        "colab_type": "code",
        "outputId": "2dcb1970-cf86-40af-f98e-e012043e88e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# make predictions on the test set\n",
        "preds = model.predict(testX)\n",
        " \n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
        "\ttarget_names=labelNames))\n",
        " \n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         top       0.89      0.88      0.88      1000\n",
            "     trouser       0.99      0.98      0.99      1000\n",
            "    pullover       0.92      0.89      0.91      1000\n",
            "       dress       0.93      0.94      0.94      1000\n",
            "        coat       0.87      0.93      0.90      1000\n",
            "      sandal       0.99      0.99      0.99      1000\n",
            "       shirt       0.80      0.80      0.80      1000\n",
            "     sneaker       0.96      0.98      0.97      1000\n",
            "         bag       0.99      0.99      0.99      1000\n",
            "  ankle boot       0.99      0.96      0.97      1000\n",
            "\n",
            "   micro avg       0.93      0.93      0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2NxqJRqMpI58",
        "colab_type": "code",
        "outputId": "4a1e36c9-1e49-4496-dfc4-28d1d702f345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# initialize our list of output images\n",
        "images = []\n",
        " \n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
        "\t# classify the clothing\n",
        "\tprobs = model.predict(testX[np.newaxis, i])\n",
        "\tpreds = probs.argmax(axis=1)\n",
        "\tlabel = labelNames[preds[0]]\n",
        " \n",
        "\t# extract the image from the testData if using \"channels_first\"\n",
        "\t# ordering\n",
        "\tif K.image_data_format() == \"channels_first\":\n",
        "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
        " \n",
        "\t# otherwise we are using \"channels_last\" ordering\n",
        "\telse:\n",
        "\t\timage = (testX[i] * 255).astype(\"uint8\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-188dd3c100ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# randomly select a few testing fashion items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# classify the clothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testY' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HBcfk8MgpJGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the text label color as green (correct)\n",
        "\tcolor = (0, 255, 0)\n",
        " \n",
        "\t# otherwise, the class label prediction is incorrect\n",
        "\tif preds[0] != np.argmax(testY[i]):\n",
        "\t\tcolor = (0, 0, 255)\n",
        " \n",
        "\t# merge the channels into one image and resize the image from\n",
        "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
        "\t# predicted label on the image\n",
        "\timage = cv2.merge([image] * 3)\n",
        "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "\t\tcolor, 2)\n",
        " \n",
        "\t# add the image to our list of output images\n",
        "\timages.append(image)\n",
        " \n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JaQyt37kQFMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2Xd_onqNNvC",
        "colab_type": "code",
        "outputId": "e21535f3-304a-4d26-af9a-3a35deb891b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cv2.imwrite('img.jpg', montage)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "nxX6NWIhNQo1",
        "colab_type": "code",
        "outputId": "a6558163-a1e2-426a-a793-e5b77e8a4775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img.jpg  plot.png  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dYJaNr73NKu-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im = cv2.imread('img.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nodr4i_GQpRK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsfUKdOuQt0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}